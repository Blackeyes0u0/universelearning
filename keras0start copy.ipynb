{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "\n",
    "#.add()\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=64, activation ='relu',input_dim=100))\n",
    "model.add(Dense(units=10, activation ='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀 추가하기\n",
    "# - 현재 셀 위에 추가: (command 모드) a\n",
    "# - 현재 셀 아래 추가: (command 모드) b\n",
    " \n",
    "# 셀 삭제하기\n",
    "# - 현재 셀 삭제: (command 모드) dd\n",
    "# - 셀 제거 취소하기: (command 모드) z\n",
    "\n",
    "# 셀 복사하기\n",
    "# - 현재 셀 복사: (command 모드) c\n",
    "# 셀 붙여넣기\n",
    "\n",
    "# - 현재 셀 위에 붙여 넣기: (command 모드) Shift + v\n",
    "# - 현재 셀 아래 붙여 넣기: (command 모드) v\n",
    "\n",
    "# 셀 이동시키기\n",
    "# - 위아래 버튼을 클릭해서 현재 셀을 이동시킬 수 있습니다.\n",
    "\n",
    "# 모든주석처리 command + /\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i like the model\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sequential model with 3layers\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2,activation='relu',name=\"layer1\"),\n",
    "        layers.Dense(3,activation='relu',name=\"layer2\"),\n",
    "        layers.Dense(4,name=\"layer3\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# call model on a test input\n",
    "x = tf.ones((3,3))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation='relu'),\n",
    "        layers.Dense(3, activation='relu'),\n",
    "        layers.Dense(4),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loss\n",
    "model.compile(loss='mean_squared_error',optimizer='sgd')\n",
    "from keras import losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='sgd',\n",
    "              metrics=[metrics.mae, metrics.categorical_accuracy])\n",
    "\n",
    "# 측정 가능 항목\n",
    "# binary_acc\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Activation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000011?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000011?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m64\u001b[39m, kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,)))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000011?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39madd(Activation(\u001b[39m'\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000011?line=6'>7</a>\u001b[0m sgd \u001b[39m=\u001b[39m optimizers\u001b[39m.\u001b[39mSGD(lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m, decay\u001b[39m=\u001b[39m\u001b[39m1e-6\u001b[39m, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, nesterov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000011?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39msgd)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Activation' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras import optimizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juniverse/opt/anaconda3/envs/akihabara_deep/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "# All parameter gradients will be clipped to\n",
    "# a maximum norm of 1.\n",
    "sgd = optimizers.SGD(lr=0.01, clipnorm=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizer_v2.rmsprop.RMSprop at 0x7fa92e1049d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "# 확률적 경사 하강법(Stochastic Gradient Descent, SGD) 옵티마이저.\n",
    "\n",
    "# 모멘텀과 네스테로프 모멘텀(Nesterov momentum), 그리고 학습률 감소 기법(learning rate decay)을 지원합니다.\n",
    "\n",
    "# lr: 0보다 크거나 같은 float 값. 학습률.\n",
    "# momentum: 0보다 크거나 같은 float 값. SGD를 적절한 방향으로 가속화하며, 흔들림(진동)을 줄여주는 매개변수입니다.\n",
    "# decay: 0보다 크거나 같은 float 값. 업데이트마다 적용되는 학습률의 감소율입니다.\n",
    "# nesterov: 불리언. 네스테로프 모멘텀의 적용 여부를 설정합니다.\n",
    "\n",
    "keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "\n",
    "# RMSProp을 사용할 때는 학습률을 제외한 모든 인자의 기본값을 사용하는 것이 권장됩니다.\n",
    "\n",
    "# 일반적으로 순환 신경망(Recurrent Neural Networks)의 옵티마이저로 많이 사용됩니다.\n",
    "\n",
    "# 인자\n",
    "\n",
    "# lr: 0보다 크거나 같은 float 값. 학습률.\n",
    "# rho: 0보다 크거나 같은 float 값.\n",
    "# epsilon: 0보다 크거나 같은 float형 fuzz factor. None인 경우 K.epsilon()이 사용됩니다.\n",
    "# decay: 0보다 크거나 같은 float 값. 업데이트마다 적용되는 학습률의 감소율입니다.\n",
    "# 참고\n",
    "\n",
    "# rmsprop: Divide the gradient by a running average of its recent magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activatioin \n",
    "\n",
    "#Activations는 Activation 층이나 앞선 층에서 지원하는 모든 activation argument로 이용 가능합니다:\n",
    "\n",
    "from keras.layers import Activation, Dense\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "#이것은 다음과 같습니다:\n",
    "\n",
    "model.add(Dense(64, activation='tanh'))\n",
    "#여러분은 Tensorflow/Theano/CNTK 의 element-wise 함수도 활성함수로 이용할 수 있습니다:\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "model.add(Dense(64, activation=K.tanh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" 내적 \"\"\"\n",
    "A = np.array([[1,2], [3,4]])\n",
    "A.shape\n",
    "\n",
    "B = np.array([[5,6], [7,8]])\n",
    "B.shape\n",
    "\n",
    "np.dot(A,B)\n",
    "\n",
    "#array([[19, 22],\n",
    "#       [43, 50]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7 1.1] [0.57444252 0.66818777 0.75026011]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 간단한 신경망 구현 \n",
    "    입력층에서 1층으로 가는 신호 \n",
    "    첫 번째 히든 레이어의 노드 수는 3개\n",
    "\"\"\"\n",
    "\n",
    "def sigmoid(num) : \n",
    "    return 1/(1+np.exp(-num))\n",
    "\n",
    "X = np.array([1.0,0.5]) # 입력이 2개 (x1, x2)\n",
    "W1 = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]]) # 입력에 대응하는 weights \n",
    "B1 = np.array([0.1,0.2,0.3]) # bias\n",
    "\n",
    "A1 = np.dot(X,W1) + B1\n",
    "Z1 = sigmoid(A1) # 첫 번째 레이어의 최종 아웃풋\n",
    "\n",
    "print(A1,Z1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31682708 0.69627909]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" 1층에서 2층으로 가는 신호 구현\n",
    "\"\"\"\n",
    "W2 = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])\n",
    "B2 = np.array([0.1,0.2])\n",
    "\n",
    "A2 = np.dot(Z1, W2) + B2\n",
    "Z2 = sigmoid(A2)\n",
    "\n",
    "\n",
    "\"\"\" 2층에서 출력층으로 가는 신호 구현\n",
    "\"\"\"\n",
    "\n",
    "# 출력층의 활성화 함수로 항등함수를 쓴다. \n",
    "# 회귀의 경우 출력층의 활성화 함수로 일반적으로 항등항수를  쓴다.\n",
    "# 2-class classification에서는 sigmoid\n",
    "# 3-class 이상의 classification에서는 softmax를 쓴다.\n",
    "def identity_function(x) :\n",
    "    return x\n",
    "\n",
    "W3 = np.array([[0.1,0.3],[0.2,0.4]])\n",
    "B3 = np.array([0.1,0.2])\n",
    "\n",
    "\n",
    "A3 = np.dot(Z2, W3) + B3\n",
    "Y = identity_function(A3)\n",
    "print(Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j9/psjfyfss16v_xrrj6mh5sw0h0000gn/T/ipykernel_22298/3898481477.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return y.astype(np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\"\"\" 일반적인 step_function \"\"\"\n",
    "def step_function(x) : \n",
    "    if x > 0 :\n",
    "        return 1\n",
    "    else : \n",
    "        return 0\n",
    "\n",
    "\"\"\" numpy의 트릭을 사용한 step function 구현 \"\"\"\n",
    "def step_function_np(x) : \n",
    "    y = x > 0\n",
    "    # boolean을 int로 변환하면 True = 1, False = 0이 된다.\n",
    "    # numpy 배열의 type을 변경할 때 .astype을 쓴다.\n",
    "    return y.astype(np.int)\n",
    "\n",
    "x = np.arange(-5.0, 5.0, 0.1) # -5.0부터 5.0까지 0.1 간격의 numpy array 생성\n",
    "y = step_function_np(x)\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.ylim(-0.1,1.1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sigmoid(x) :\n",
    "    return 1 / (1+np.exp(-x))\n",
    "\n",
    "x = np.array([-1.0, 1.0, 2.0])\n",
    "\n",
    "# numpy broadcast 기능으로 인해 정상수행\n",
    "sigmoid(x)\n",
    "\n",
    "x=np.arange(-10,10,0.1)\n",
    "plt.plot(x,sigmoid(x))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(x) : \n",
    "    return np.maximum(0, x)\n",
    "\n",
    "x=np.arange(-10,10,0.1)\n",
    "plt.plot(x,relu(x))\n",
    "plt.ylim(-1,10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# soft max \n",
    "\"\"\" Softmax 구현 \"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def softmax(a) :\n",
    "    exp_a = np.exp(a)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    \n",
    "    return y\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "print(softmax(a)) # softmax 결과값 출력\n",
    "print(sum(softmax(a))) # softmax 결과값들의 합은 1이 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWord Embedding\\n\\nWord Embedding이란 Deep Learning 분야, 이 중에서도 특히 자연어처리에서 필수적으로 알아야할 개념이다. Word Embedding은 Word를 R차원의 Vector로 매핑시켜주는 것을 말한다.\\n\\n예를 들어 위와 같이 cat이나 mat같은 단어를 특정 차원의 벡터로 바꾸어주는 것이다. 이렇게 단어를 벡터로 바꾸어주는 것은 하나의 Matrix이다. 이를 W라 부른다. W 함수는 매우 중요하다. 이를 통해 단어가 의미 있는 벡터로 변한다. 비슷한 두 개의 단어는 비슷한 벡터로 바뀐다던지 하는 식으로 말이다. W는 Learning을 통해 학습할 수 있다.\\n예를 들어, 5000개의 단어로 이루어진 단어 세트가 있으면 각각의 단어는 [0,0,0,1,0 ... 0,0,0] (5000열) 과 같이 나타낼 수 있다. 이 때 각각의 단어를 Word Embedding을 통해 32차원 벡터로 나타내고자 하면 W의 차원은 5000*32이다. 이를 학습하여 [0.2,0,4,0.5 ... 0.8,8] 과 같은 32차원의 벡터를 형성해낸다.\\nWord Embedding은 다음과 같은 놀라운 특성도 가질 수 있다.\\n\\nwoman을 나타내는 벡터와 man을 나타내는 벡터의 차이는 남녀의 차이를 나타내는 벡터이다. 이것이 aunt와 uncle의 차이를 만들어낸다. 예를 들어 he is a man는 옳은문장 she is a man은 틀린 문장을 구분하는 classifier에서 aunt와 uncle에 대해서도 똑같은 일을 할 수 있게 만든다.\\n\\n참고\\n\\n\\n\\nhttp://colah.github.io/posts/2014-07-NLP-RNNs-Representations/\\n\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Word Embedding\n",
    "\n",
    "Word Embedding이란 Deep Learning 분야, 이 중에서도 특히 자연어처리에서 필수적으로 알아야할 개념이다. Word Embedding은 Word를 R차원의 Vector로 매핑시켜주는 것을 말한다.\n",
    "\n",
    "예를 들어 위와 같이 cat이나 mat같은 단어를 특정 차원의 벡터로 바꾸어주는 것이다. 이렇게 단어를 벡터로 바꾸어주는 것은 하나의 Matrix이다. 이를 W라 부른다. W 함수는 매우 중요하다. 이를 통해 단어가 의미 있는 벡터로 변한다. 비슷한 두 개의 단어는 비슷한 벡터로 바뀐다던지 하는 식으로 말이다. W는 Learning을 통해 학습할 수 있다.\n",
    "예를 들어, 5000개의 단어로 이루어진 단어 세트가 있으면 각각의 단어는 [0,0,0,1,0 ... 0,0,0] (5000열) 과 같이 나타낼 수 있다. 이 때 각각의 단어를 Word Embedding을 통해 32차원 벡터로 나타내고자 하면 W의 차원은 5000*32이다. 이를 학습하여 [0.2,0,4,0.5 ... 0.8,8] 과 같은 32차원의 벡터를 형성해낸다.\n",
    "Word Embedding은 다음과 같은 놀라운 특성도 가질 수 있다.\n",
    "\n",
    "woman을 나타내는 벡터와 man을 나타내는 벡터의 차이는 남녀의 차이를 나타내는 벡터이다. 이것이 aunt와 uncle의 차이를 만들어낸다. 예를 들어 he is a man는 옳은문장 she is a man은 틀린 문장을 구분하는 classifier에서 aunt와 uncle에 대해서도 똑같은 일을 할 수 있게 만든다.\n",
    "\n",
    "참고\n",
    "\n",
    "\n",
    "\n",
    "http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "class NearestNeighbor(object): \n",
    "    def __init__(self): \n",
    "        pass \n",
    "    def train(self, X, y): \n",
    "        \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\" \n",
    "        # the nearest neighbor classifier simply remembers all the training data \n",
    "        self.Xtr = X \n",
    "        self.ytr = y \n",
    "        def predict(self, X): \n",
    "            \"\"\" X is N x D where each row is an example we wish to predict label for \"\"\" \n",
    "            num_test = X.shape[0] \n",
    "            # lets make sure that the output type matches the input type \n",
    "            Ypred = np.zeros(num_test, dtype = self.ytr.dtype) \n",
    "            # loop over all test rows \n",
    "            for i in xrange(num_test): \n",
    "                # find the nearest training image to the i'th test image # using the L1 distance (sum of absolute value differences) \n",
    "                distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1) \n",
    "                min_index = np.argmin(distances) \n",
    "                # get the index with smallest distance \n",
    "                Ypred[i] = self.ytr[min_index] \n",
    "                # predict the label of the nearest example \n",
    "            return Ypred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtr_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000030?line=0'>1</a>\u001b[0m \u001b[39m# recall Xtr_rows is 50,000 x 3072 matrix\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000030?line=1'>2</a>\u001b[0m Xval_rows \u001b[39m=\u001b[39m Xtr_rows[:\u001b[39m1000\u001b[39m, :] \u001b[39m# take first 1000 for validation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000030?line=2'>3</a>\u001b[0m Yval \u001b[39m=\u001b[39m Ytr[:\u001b[39m1000\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000030?line=3'>4</a>\u001b[0m Xtr_rows \u001b[39m=\u001b[39m Xtr_rows[\u001b[39m1000\u001b[39m:, :] \u001b[39m# keep last 49,000 for train\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtr_rows' is not defined"
     ]
    }
   ],
   "source": [
    "# recall Xtr_rows is 50,000 x 3072 matrix\n",
    "Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation\n",
    "Yval = Ytr[:1000]\n",
    "Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train\n",
    "Ytr = Ytr[1000:]\n",
    "\n",
    "# find hyperparameters that work best on the validation set\n",
    "validation_accuracies = []\n",
    "for k in [1, 3, 5, 10, 20, 50, 100]:\n",
    "  \n",
    "  # use a particular value of k and evaluation on validation data\n",
    "  nn = NearestNeighbor()\n",
    "  nn.train(Xtr_rows, Ytr)\n",
    "  # here we assume a modified NearestNeighbor class that can take a k as input\n",
    "  Yval_predict = nn.predict(Xval_rows, k = k)\n",
    "  acc = np.mean(Yval_predict == Yval)\n",
    "  print('accuracy: %f' % (acc,))\n",
    "\n",
    "  # keep track of what works on the validation set\n",
    "  validation_accuracies.append((k, acc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '\\x1f'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb Cell 25'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000032?line=5'>6</a>\u001b[0m \u001b[39m# load the dataset\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000032?line=7'>8</a>\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/Users/juniverse/Downloads/mnist.pkl.gz\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000032?line=8'>9</a>\u001b[0m train_set, vlaid_set, test_set \u001b[39m=\u001b[39m cPickle\u001b[39m.\u001b[39;49mload(f, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlatin1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000032?line=9'>10</a>\u001b[0m f\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juniverse/vscode/dl/GN_Drive/keras0start.ipynb#ch0000032?line=11'>12</a>\u001b[0m x_train, y_train \u001b[39m=\u001b[39m train_set\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\\x1f'."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gzip, numpy\n",
    "import pickle as cPickle\n",
    "import pandas as pd\n",
    "\n",
    "# load the dataset\n",
    "\n",
    "f = open('/Users/juniverse/Downloads/mnist.pkl.gz','rb')\n",
    "train_set, vlaid_set, test_set = cPickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "x_train, y_train = train_set\n",
    "x_test, y_text = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import gzip, numpy\n",
    "import pickle as cPickle\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "f = open('/Users/juniverse/Downloads/mnist.pkl', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "x_train, y_train = train_set\n",
    "x_test, y_test = test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape : (50000, 784)\n",
      "y_train shape:  (50000, 10)\n",
      "x_test shape:  (10000, 784)\n",
      "y_test shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# pickle로 불러온 변수에는 train_set, valid_set, test_set이 나뉘어져 있기 때문에 위와 같이 load하면 알아서 training, validation, test set으로 나눌 수 있습니다. 또한 각각은 튜플 자료구조형으로 또 다시 x, y로 나뉘어져 있기 때문에 x_train, y_train = train_set 구문을 통해 feature과 label을 분리할 수 있습니다. 이렇게 데이터를 빠르게 training을 적용할 수 있는 형태로 만들어낼 수 있다는 것이 pickle 파일의 좋은 점입니다. 하지만 예제가 아닌 실제 머신러닝 모델을 구축할 때는 이러한 과정을 모두 직접하여야 합니다. 이미지 파일을 읽어들여야하고 또 이것을 적절한 사이즈의 numpy array로 바꾸어야합니다. \n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "# label  -> one hot encoding   \n",
    "# https://wikidocs.net/22647\n",
    "# in tensorflow   label must -> one hot encoding\n",
    "\n",
    "print('x_train shape :',x_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('x_test shape: ',x_test.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "x = tf.placeholder('float', [None, 784])  # data num : None , feature : 784\n",
    "W = tf.Variable(tf.zeros([784,10])) # weight matrix input layer : 784 output layer :10    ## reset to 0\n",
    "b = tf.Variable(tf.zeros([10])) # output layer : 10 ## reset to 0\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)  # x and W matrix multiply + bias  \n",
    "#  y = perdiction value\n",
    "y_ = tf.placeholder('float', [None, 10]) \n",
    "\n",
    "# classification : use cross entropy\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y)) \n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch training\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 100\n",
    "training_epochs = 3\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    batch_count=int(x_train.shape[0]/100) # num of batch\n",
    "    for i in range(batch_count):\n",
    "        # read batch size\n",
    "        batch_xs ,batch_ys= x_train[i*batch_size:i*batch_size+batch_size],y_train[i*batch_size:i*batch_size+batch_size]\n",
    "        #  regulate w, b variable    training\n",
    "        sess.run(train_step, feed_dict={x : batch_xs, y_ : batch_ys})\n",
    "        # [ True, False , False, True , False, True ] like this bollean vector\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "\n",
    "        # [ 1 01 0101010 010] convert  and evaluate average\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "\n",
    "        # if read 5 batch training accuracy print\n",
    "        if i % 100==0:\n",
    "            print(str(epoch+1)+'epoch'+str(i)+'batch',sess.run(accuracy,feed_dict={x:x_test[0:100],y_:y_test[0:100]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 부분을 이해하기 위해서는 우선 배치 트레이닝에 대하여 알아야 합니다. 배치 트레이닝이란 트레이닝 데이터를 일정 사이즈로 쪼갠 미니 배치(mini batch)를 통해 Gradient Descent를 하는 방법입니다. 일반적인 Gradient Descent 방법은 전체 트레이닝 데이터를 한 번 쭉 보고 gradient를 구한 후 weights와 bias를 '한 번' 업데이트 시킵니다. 하지만 이런 방법은 computation cost가 높습니다. 하지만 미니 배치를 이용한 방법은 전체 데이터의 샘플인 미니 배치를 통해 전체 데이터를 근사 시킵니다. 그리고 이것만 보고 gradient를 구한 후 weight, bias를 업데이트 시킵니다. 예를 들어 배치 사이즈가 128이면 128개의 데이터 샘플들만 보고 gradient를 구한 후 weight, bias를 업데이트 하게 됩니다. 이전 방식에 비해 훨씬 빠르게 weight를 업데이트 시킬 수 있죠. 이렇게 weight를 구하는 방식은 Stochastic Gradient Descent 방법이라고 부릅니다. 실제로 일반적인 Gradient Descent 방법보다는 Stochastic Gradient Descent 방법이 더 많이 쓰입니다. 팁으로는 배치 사이즈는 메모리가 허용하는 범위 내에서 최대한 크게 잡는 것이 좋습니다. 그리고 보통 배치사이즈는 128, 256, 512와 같이 2의 배수로 잡는 경우가 많은데 혹자는 이를 CPU 연산의 효율을 증가시킨다고 합니다. 하지만 111, 234와 같이 아무 배치 사이즈나 잡아도 트레이닝은 잘 합니다.\n",
    "# 이러한 배치 트레이닝의 방식을 이해한다면 위의 텐서플로우 코드도 어렵지 않게 이해할 수 있습니다. \n",
    "\n",
    "sess= tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 마지막 트레이닝 파트입니다. 미니 배치를 구할 때 전체 데이터에서 샘플 데이터를 랜덤으로 뽑는 방식도 있지만 여기서는 그냥 순차적으로 배치를 만들었습니다. 0번부터 100번까지를 1배치, 101번부터 200번까지를 2배치와 같은 방식으로 말입니다. (사실 데이터의 순서에 어떠한 규칙이 있다면 이러한 방식은 좋지 않을 수 있습니다.) epoch만큼 전체 데이터를 보아아햐고 또 배치 사이즈만큼 전체 데이터를 쪼개야하니까 이중 for문을 써야하는 것을 알 수 있습니다. 그리고 두 번째 for문에서는 i라는 인덱스와 batch_size라는 변수를 이용하여 원하는 만큼 데이터를 계속해서 불러온후 Gradient Descent를 하면됩니다. 각각의 문장이 의미하는바는 코드에 주석으로 써두었습니다. \n",
    "\n",
    "\n",
    "\n",
    "# 5. 결과\n",
    "\n",
    "\n",
    "#  배치 트레이닝을 100번 했을 때 이미 정확도가 0.93에 육박하는 것을 알 수 있습니다.\n",
    "\n",
    "# 트레이닝이 끝났을 때의 최종 정확도는 0.96 이었습니다. 이미 100번 트레이닝을 했을 때 정확도가 0.93이었기 때문에 그 이상의 training은 의미가 없었을지도 모릅니다. 지금은 validation과정 없이 마구잡이로 트레이닝을 했지만 보통은 언제 training을 끝내야하는지 잘 선택하여야합니다. 계속되는 불필요한 training은 overfitting을 유발할 수 있기 때문입니다. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "daa4b12c7c0dfbea8a86e5c8683f87cd86f2768d8d85b18e100265b2a7dc8fca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('akihabara_deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
